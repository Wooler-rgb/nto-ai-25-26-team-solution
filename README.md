# Решение задачи рекомендации книг

**Финальный скор: 0.889 NDCG@20**

## Подход

### Модель
- **CatBoost Ranker** с функцией потерь PairLogitPairwise
- Ансамбль из 4 моделей с разными random seed
- **Rank-based усреднение** (более робастное чем усреднение скоров)

### Стратегия негативного сэмплирования
- **150 негативов на пользователя** из топ-800 популярных книг
- Ключевой инсайт: негативы должны иметь богатые фичи (популярность, взаимодействия и т.д.)
- Случайные/непопулярные негативы показали плохой результат (0.59 на паблике)

### Признаки (16 штук)

| Признак | Описание |
|---------|----------|
| times_read | Сколько раз книгу прочитали |
| total_interactions | Всего взаимодействий с книгой |
| read_rate | Доля прочтений от взаимодействий |
| avg_user_rating | Средний рейтинг книги от пользователей |
| unique_users | Количество уникальных пользователей |
| user_books_read | Сколько книг прочитал пользователь |
| user_read_rate | Доля прочтений пользователя |
| user_avg_rating | Средний рейтинг пользователя |
| publication_year | Год публикации книги |
| avg_rating | Глобальный средний рейтинг книги |
| book_age | Возраст книги (лет с публикации) |
| age | Возраст пользователя |
| gender | Пол пользователя |
| genre_match | Пересечение жанров пользователя и книги |
| popularity | log(1 + total_interactions) |
| rating_compatibility | 1 - |рейтинг_книги - средний_рейтинг_юзера| / 5 |

## Ключевые инсайты

1. **Источник негативов важнее их количества**
   - Популярные книги (топ-800) как негативы: 0.88+
   - Случайные книги как негативы: 0.59 (провал)
   - Книги из candidates как негативы: 0.59

2. **Низкая валидация != высокий паблик**
   - Слишком низкая валидация = модель не учится
   - Оптимально: валидация ~0.85-0.87

3. **Распределение книг в candidates**
   - Только 4.6% из топ-800
   - 34% холодных книг (нет в train)
   - 42.7% с рангом 5000+

4. **Rank-based ансамбль лучше score-based**
   - Более устойчив к разнице в масштабах скоров
   - Дал +0.2% улучшение

## Структура файлов

```
ai kz/
├── README.md           # Этот файл
├── solution.ipynb      # Финальное решение
├── data/               # Директория с данными
│   ├── train.csv       # Обучающие взаимодействия
│   ├── books.csv       # Метаданные книг
│   ├── users.csv       # Метаданные пользователей
│   ├── book_genres.csv # Связи книга-жанр
│   ├── candidates.csv  # Кандидаты для каждого тестового юзера
│   └── targets.csv     # ID тестовых пользователей
└── submission.csv      # Финальный сабмишен
```

## Инструкция по воспроизведению

### 1. Установка зависимостей

```bash
pip install pandas numpy catboost scikit-learn jupyter
```

### 2. Подготовка данных

Поместите файлы данных в папку `data/`:
- train.csv
- books.csv
- users.csv
- book_genres.csv
- candidates.csv
- targets.csv

### 3. Запуск решения

```bash
jupyter notebook solution.ipynb
```

Запустите все ячейки по порядку (Run All).

### 4. Результат

После выполнения будет создан файл `submission.csv` с предсказаниями.

## Время выполнения

- Подготовка данных: ~2 минуты
- Обучение 4 моделей: ~12-15 минут (GPU)
- Предсказания: ~3 минуты

**Общее время: ~20 минут**

## Прогресс результатов

| Эксперимент | Val NDCG | Public NDCG |
|-------------|----------|-------------|
| Baseline (15 neg) | 0.93 | 0.86 |
| 100 neg | 0.87 | 0.88 |
| 150 neg + ens3 | 0.85 | 0.887 |
| 150 neg + rank ens4 | 0.84 | **0.889** |
